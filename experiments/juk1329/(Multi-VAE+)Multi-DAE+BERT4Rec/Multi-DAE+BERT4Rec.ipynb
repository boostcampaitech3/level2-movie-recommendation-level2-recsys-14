{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQG9hL8-UQUP"
      },
      "source": [
        "# Multi-DAE + BERT4Rec\n",
        "\n",
        "- 다음 [코드](https://github.com/younggyoseo/vae-cf-pytorch)를 기반으로 작성되었습니다.\n",
        "\n",
        "아래 Inference 부분에서 ensemble 과정을 진행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7CfnRw7U59C"
      },
      "source": [
        "## 1. 초기 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "bQj6k1mSbxaz"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd #버전 1.0.1에서 실행해야 함.\n",
        "import numpy as np\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMWYLPFIjon8"
      },
      "source": [
        "## 데이터 다운로드\n",
        "이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요. \n",
        "- 데이터 URL은 변경될 수 있습니다.\n",
        "- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ3W0udmbxa3",
        "outputId": "838a89da-f5c9-4d47-c5a9-638132ed8754"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 각종 파라미터 세팅\n",
        "parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n",
        "\n",
        "\n",
        "parser.add_argument('--data', type=str, default='data/train/',\n",
        "                    help='Movielens dataset location')\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=1e-4,\n",
        "                    help='initial learning rate')\n",
        "parser.add_argument('--wd', type=float, default=0.00,\n",
        "                    help='weight decay coefficient')\n",
        "parser.add_argument('--batch_size', type=int, default=1600,#500,\n",
        "                    help='batch size')\n",
        "parser.add_argument('--epochs', type=int, default=20, #원래 20\n",
        "                    help='upper epoch limit')\n",
        "parser.add_argument('--total_anneal_steps', type=int, default=200000,\n",
        "                    help='the total number of gradient updates for annealing')\n",
        "parser.add_argument('--anneal_cap', type=float, default=0.2,\n",
        "                    help='largest annealing parameter')\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--cuda', action='store_true',\n",
        "                    help='use CUDA')\n",
        "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
        "                    help='report interval')\n",
        "parser.add_argument('--save', type=str, default='model.pt',\n",
        "                    help='path to save the final model')\n",
        "args = parser.parse_args([])\n",
        "\n",
        "# Set the random seed manually for reproductibility.\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n",
        "if torch.cuda.is_available():\n",
        "    args.cuda = True\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o1fvXqFWE_G"
      },
      "source": [
        "## 2. 데이터 전처리\n",
        "\n",
        "MovieLens (user, item, timestamp)데이터를 전처리하는 과정입니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cgvNoy1Ybxa6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "\n",
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "\n",
        "    return count\n",
        "\n",
        "# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상) \n",
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'item')\n",
        "        tp = tp[tp['item'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'user')\n",
        "        tp = tp[tp['user'].isin(usercount.index[usercount >= min_uc])]\n",
        "\n",
        "    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n",
        "    return tp, usercount, itemcount\n",
        "\n",
        "#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수\n",
        "def split_train_test_proportion(data, test_prop=0.2): #원래 0.2\n",
        "    data_grouped_by_user = data.groupby('user')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "    \n",
        "    for _, group in data_grouped_by_user:\n",
        "        n_items_u = len(group)\n",
        "        \n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        \n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "    \n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "\n",
        "    return data_tr, data_te\n",
        "\n",
        "def numerize(tp, profile2id, show2id):\n",
        "    uid = tp['user'].apply(lambda x: profile2id[x])\n",
        "    sid = tp['item'].apply(lambda x: show2id[x])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVFoRHrmVQsp",
        "outputId": "b2bf72b7-9ba4-4468-e270-91a4c3a79b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load and Preprocess Movielens dataset\n",
            "원본 데이터\n",
            "            user   item        time\n",
            "0            11   4643  1230782529\n",
            "1            11    170  1230782534\n",
            "2            11    531  1230782539\n",
            "3            11    616  1230782542\n",
            "4            11   2140  1230782563\n",
            "...         ...    ...         ...\n",
            "5154466  138493  44022  1260209449\n",
            "5154467  138493   4958  1260209482\n",
            "5154468  138493  68319  1260209720\n",
            "5154469  138493  40819  1260209726\n",
            "5154470  138493  27311  1260209807\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\n",
            "            user   item        time\n",
            "0            11   4643  1230782529\n",
            "1            11    170  1230782534\n",
            "2            11    531  1230782539\n",
            "3            11    616  1230782542\n",
            "4            11   2140  1230782563\n",
            "...         ...    ...         ...\n",
            "5154466  138493  44022  1260209449\n",
            "5154467  138493   4958  1260209482\n",
            "5154468  138493  68319  1260209720\n",
            "5154469  138493  40819  1260209726\n",
            "5154470  138493  27311  1260209807\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "유저별 리뷰수\n",
            " user\n",
            "11        376\n",
            "14        180\n",
            "18         77\n",
            "25         91\n",
            "31        154\n",
            "         ... \n",
            "138473     63\n",
            "138475    124\n",
            "138486    137\n",
            "138492     68\n",
            "138493    314\n",
            "Length: 31360, dtype: int64\n",
            "아이템별 리뷰수\n",
            " item\n",
            "1         12217\n",
            "2          3364\n",
            "3           734\n",
            "4            43\n",
            "5           590\n",
            "          ...  \n",
            "118700       54\n",
            "118900       60\n",
            "118997       52\n",
            "119141      122\n",
            "119145       78\n",
            "Length: 6807, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Load and Preprocess Movielens dataset\")\n",
        "# Load Data\n",
        "DATA_DIR = args.data\n",
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n",
        "print(\"원본 데이터\\n\", raw_data)\n",
        "\n",
        "# Filter Data\n",
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n",
        "#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n",
        "print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n",
        "\n",
        "print(\"유저별 리뷰수\\n\",user_activity)\n",
        "print(\"아이템별 리뷰수\\n\",item_popularity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T1dTsWUrffP",
        "outputId": "660bfff0-40ea-4f80-cff4-f61d711867bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(BEFORE) unique_uid: Int64Index([    11,     14,     18,     25,     31,     35,     43,     50,\n",
            "                58,     60,\n",
            "            ...\n",
            "            138459, 138461, 138470, 138471, 138472, 138473, 138475, 138486,\n",
            "            138492, 138493],\n",
            "           dtype='int64', name='user', length=31360)\n",
            "(AFTER) unique_uid: Int64Index([ 27968,  67764,   2581,  82969, 137831,  48639,  97870,  40424,\n",
            "             46835,  79570,\n",
            "            ...\n",
            "            114284,   9009,  21165,  33920,  22054, 135379, 125855,  41891,\n",
            "             15720,  17029],\n",
            "           dtype='int64', name='user', length=31360)\n",
            "훈련 데이터에 사용될 사용자 수: 25088\n",
            "검증 데이터에 사용될 사용자 수: 3136\n",
            "테스트 데이터에 사용될 사용자 수: 3136\n"
          ]
        }
      ],
      "source": [
        "# Shuffle User Indices\n",
        "unique_uid = user_activity.index\n",
        "print(\"(BEFORE) unique_uid:\",unique_uid)\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]\n",
        "print(\"(AFTER) unique_uid:\",unique_uid)\n",
        "\n",
        "n_users = unique_uid.size #31360\n",
        "n_heldout_users = 3136#3000\n",
        "\n",
        "\n",
        "# Split Train/Validation/Test User Indices\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]\n",
        "\n",
        "#주의: 데이터의 수가 아닌 사용자의 수입니다!\n",
        "print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n",
        "print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n",
        "print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yBsRCRqtPz6",
        "outputId": "2d3e6c1d-5d84-4a90-c0af-e0fb5786ea53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "##훈련 데이터에 해당하는 아이템들\n",
        "#Train에는 전체 데이터를 사용합니다.\n",
        "train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n",
        "\n",
        "##아이템 ID\n",
        "unique_sid = pd.unique(train_plays['item'])\n",
        "\n",
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
        "\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)\n",
        "\n",
        "#Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n",
        "vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n",
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
        "\n",
        "test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n",
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
        "\n",
        "\n",
        "\n",
        "train_data = numerize(train_plays, profile2id, show2id)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
        "\n",
        "\n",
        "vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
        "\n",
        "vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
        "\n",
        "test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
        "\n",
        "test_data_te = numerize(test_plays_te, profile2id, show2id)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkdg2OkjqVUM",
        "outputId": "ded2bbf9-c319-4546-aabd-3b97b6e7a01a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           uid   sid\n",
            "0        11825     0\n",
            "1        11825     1\n",
            "2        11825     2\n",
            "3        11825     3\n",
            "4        11825     4\n",
            "...        ...   ...\n",
            "5154466  10783   477\n",
            "5154467  10783  1325\n",
            "5154468  10783   331\n",
            "5154469  10783   558\n",
            "5154470  10783  1922\n",
            "\n",
            "[4125303 rows x 2 columns]\n",
            "           uid   sid\n",
            "376      26554   440\n",
            "377      26554   741\n",
            "378      26554  1407\n",
            "379      26554   193\n",
            "380      26554  1041\n",
            "...        ...   ...\n",
            "5153247  26934   760\n",
            "5153248  26934   697\n",
            "5153249  26934  3232\n",
            "5153250  26934  1369\n",
            "5153251  26934  3679\n",
            "\n",
            "[415395 rows x 2 columns]\n",
            "           uid   sid\n",
            "382      26554  3012\n",
            "383      26554  1681\n",
            "384      26554   201\n",
            "399      26554  3177\n",
            "401      26554  3289\n",
            "...        ...   ...\n",
            "5153229  26934   737\n",
            "5153233  26934   228\n",
            "5153236  26934   235\n",
            "5153240  26934  3962\n",
            "5153243  26934  1086\n",
            "\n",
            "[102295 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#데이터 셋 확인\n",
        "print(train_data)\n",
        "print(vad_data_tr)\n",
        "print(vad_data_te)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMiq9leyWWL1"
      },
      "source": [
        "## 3. 데이터 로더 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "nxUADr9ibxa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataLoader():\n",
        "    '''\n",
        "    Load Movielens dataset\n",
        "    '''\n",
        "    def __init__(self, path):\n",
        "        \n",
        "        self.pro_dir = os.path.join(path, 'pro_sg')\n",
        "        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n",
        "\n",
        "        self.n_items = self.load_n_items()\n",
        "    \n",
        "    def load_data(self, datatype='train'):\n",
        "        if datatype == 'train':\n",
        "            return self._load_train_data()\n",
        "        elif datatype == 'validation':\n",
        "            return self._load_tr_te_data(datatype)\n",
        "        elif datatype == 'test':\n",
        "            return self._load_tr_te_data(datatype)\n",
        "        else:\n",
        "            raise ValueError(\"datatype should be in [train, validation, test]\")\n",
        "        \n",
        "    def load_n_items(self):\n",
        "        unique_sid = list()\n",
        "        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "            for line in f:\n",
        "                unique_sid.append(line.strip())\n",
        "        n_items = len(unique_sid)\n",
        "        return n_items\n",
        "    \n",
        "    def _load_train_data(self):\n",
        "        path = os.path.join(self.pro_dir, 'train.csv')\n",
        "        \n",
        "        tp = pd.read_csv(path)\n",
        "        n_users = tp['uid'].max() + 1\n",
        "\n",
        "        rows, cols = tp['uid'], tp['sid']\n",
        "        data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                                 (rows, cols)), dtype='float64',\n",
        "                                 shape=(n_users, self.n_items))\n",
        "        return data\n",
        "    \n",
        "    def _load_tr_te_data(self, datatype='test'):\n",
        "        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n",
        "        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n",
        "\n",
        "        tp_tr = pd.read_csv(tr_path)\n",
        "        tp_te = pd.read_csv(te_path)\n",
        "\n",
        "        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
        "        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
        "        return data_tr, data_te"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHhwKqXWaUZ"
      },
      "source": [
        "## 4. 모델정의\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QYlGPJTYU0ii"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MultiDAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Container module for Multi-DAE.\n",
        "\n",
        "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
        "    See Variational Autoencoders for Collaborative Filtering\n",
        "    https://arxiv.org/abs/1802.05814\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
        "        super(MultiDAE, self).__init__()\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims:\n",
        "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        else:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        \n",
        "        self.init_weights()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        h = F.normalize(input)\n",
        "        h = self.drop(h)\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def init_weights(self):\n",
        "        for layer in self.layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "\n",
        "\n",
        "class MultiVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Container module for Multi-VAE.\n",
        "\n",
        "    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n",
        "    See Variational Autoencoders for Collaborative Filtering\n",
        "    https://arxiv.org/abs/1802.05814\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
        "        super(MultiVAE, self).__init__()\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims:\n",
        "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        else:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "\n",
        "        # Last dimension of q- network is for mean and variance\n",
        "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
        "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
        "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
        "        \n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.init_weights()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        mu, logvar = self.encode(input)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "    \n",
        "    def encode(self, input):\n",
        "        h = F.normalize(input)\n",
        "        h = self.drop(h)\n",
        "        \n",
        "        for i, layer in enumerate(self.q_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.q_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "            else:\n",
        "                mu = h[:, :self.q_dims[-1]]\n",
        "                logvar = h[:, self.q_dims[-1]:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = torch.exp(0.5 * logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "    \n",
        "    def decode(self, z):\n",
        "        h = z\n",
        "        for i, layer in enumerate(self.p_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.p_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def init_weights(self):\n",
        "        for layer in self.q_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "        \n",
        "        for layer in self.p_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n",
        "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
        "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
        "\n",
        "    return BCE + anneal * KLD\n",
        "\n",
        "def loss_function_dae(recon_x, x):\n",
        "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
        "    return BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "7nEfVTktbxa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sparse2torch_sparse(data):\n",
        "    \"\"\"\n",
        "    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n",
        "    This is much faster than naive use of torch.FloatTensor(data.toarray())\n",
        "    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n",
        "    \"\"\"\n",
        "    samples = data.shape[0]\n",
        "    features = data.shape[1]\n",
        "    coo_data = data.tocoo()\n",
        "    indices = torch.LongTensor([coo_data.row, coo_data.col])\n",
        "    row_norms_inv = 1 / np.sqrt(data.sum(1))\n",
        "    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n",
        "    values = np.array([row2val[r] for r in coo_data.row])\n",
        "    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n",
        "    return t\n",
        "\n",
        "def naive_sparse2tensor(data):\n",
        "    return torch.FloatTensor(data.toarray())\n",
        "\n",
        "\n",
        "def train(model, criterion, optimizer, is_VAE = False):\n",
        "    # Turn on training mode\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    global update_count\n",
        "\n",
        "    np.random.shuffle(idxlist)\n",
        "    \n",
        "    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n",
        "        end_idx = min(start_idx + args.batch_size, N)\n",
        "        data = train_data[idxlist[start_idx:end_idx]]\n",
        "        data = naive_sparse2tensor(data).to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if is_VAE:\n",
        "          if args.total_anneal_steps > 0:\n",
        "            anneal = min(args.anneal_cap, \n",
        "                            1. * update_count / args.total_anneal_steps)\n",
        "          else:\n",
        "              anneal = args.anneal_cap\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          recon_batch, mu, logvar = model(data)\n",
        "          \n",
        "          loss = criterion(recon_batch, data, mu, logvar, anneal)\n",
        "        else:\n",
        "          recon_batch = model(data)\n",
        "          loss = criterion(recon_batch, data)\n",
        "\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        update_count += 1\n",
        "\n",
        "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
        "                    'loss {:4.2f}'.format(\n",
        "                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n",
        "                        elapsed * 1000 / args.log_interval,\n",
        "                        train_loss / args.log_interval))\n",
        "            \n",
        "\n",
        "            start_time = time.time()\n",
        "            train_loss = 0.0\n",
        "    train_loss /= len(range(0, N, args.batch_size))\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model, criterion, data_tr, data_te, is_VAE=False):\n",
        "    # Turn on evaluation mode\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    global update_count\n",
        "    e_idxlist = list(range(data_tr.shape[0]))\n",
        "    e_N = data_tr.shape[0]\n",
        "    n100_list = []\n",
        "    r10_list= []\n",
        "    r20_list = []\n",
        "    r50_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for start_idx in range(0, e_N, args.batch_size):\n",
        "            end_idx = min(start_idx + args.batch_size, N)\n",
        "            data = data_tr[e_idxlist[start_idx:end_idx]]\n",
        "            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n",
        "\n",
        "            data_tensor = naive_sparse2tensor(data).to(device)\n",
        "            if is_VAE :\n",
        "              \n",
        "              if args.total_anneal_steps > 0:\n",
        "                  anneal = min(args.anneal_cap, \n",
        "                                1. * update_count / args.total_anneal_steps)\n",
        "              else:\n",
        "                  anneal = args.anneal_cap\n",
        "\n",
        "              recon_batch, mu, logvar = model(data_tensor)\n",
        "\n",
        "              loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n",
        "\n",
        "            else :\n",
        "              recon_batch = model(data_tensor)\n",
        "              loss = criterion(recon_batch, data_tensor)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Exclude examples from training set\n",
        "            recon_batch = recon_batch.cpu().numpy()\n",
        "            recon_batch[data.nonzero()] = -np.inf\n",
        "\n",
        "            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n",
        "            r20 = Recall_at_k_batch(recon_batch, heldout_data, 20)\n",
        "            r10 = Recall_at_k_batch(recon_batch, heldout_data, 10)\n",
        "            r50 = Recall_at_k_batch(recon_batch, heldout_data, 50)\n",
        "\n",
        "            n100_list.append(n100)\n",
        "            r20_list.append(r20)\n",
        "            r10_list.append(r10)\n",
        "            r50_list.append(r50)\n",
        " \n",
        "    total_loss /= len(range(0, e_N, args.batch_size))\n",
        "    n100_list = np.concatenate(n100_list)\n",
        "    r20_list = np.concatenate(r20_list)\n",
        "    r10_list = np.concatenate(r10_list)\n",
        "    r50_list = np.concatenate(r50_list)\n",
        "\n",
        "    return total_loss, np.mean(n100_list), np.mean(r10_list), np.mean(r20_list), np.mean(r50_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOsCJbb_X9gl"
      },
      "source": [
        "## Metric 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "zxNtit6vbxa-"
      },
      "outputs": [],
      "source": [
        "import bottleneck as bn\n",
        "import numpy as np\n",
        "\n",
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    Normalized Discounted Cumulative Gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG\n",
        "\n",
        "\n",
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "    \n",
        "    #X_pred += Bert_recon ## item embedding 0.5비율로 추가\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDD7lD7sHcnH"
      },
      "source": [
        "## MultiDAE 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-E1TYVwPlzeO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(31360, 6808)\n"
          ]
        }
      ],
      "source": [
        "np_load = np.load('BERT4Rec.npy')\n",
        "Bert_recon = np_load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy1_cM9PfICH",
        "outputId": "5b0ec30e-307e-4fce-f722-3997d7571621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: adabound in /opt/conda/lib/python3.8/site-packages (0.0.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from adabound) (1.10.2)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=0.4.0->adabound) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install adabound\n",
        "import adabound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "WLYyTwToX4fm"
      },
      "outputs": [],
      "source": [
        "\n",
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "loader = DataLoader(args.data)\n",
        "\n",
        "n_items = loader.load_n_items()\n",
        "train_data = loader.load_data('train')\n",
        "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
        "test_data_tr, test_data_te = loader.load_data('test')\n",
        "\n",
        "N = train_data.shape[0]\n",
        "idxlist = list(range(N))\n",
        "\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "#p_dims = [200, 600, 1600, 3200, n_items]\n",
        "p_dims = [200, 3000, n_items]\n",
        "model = MultiDAE(p_dims).to(device)\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n",
        "optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n",
        "#https://github.com/Luolc/AdaBound\n",
        "#optimizer = optim.SGD(model.parameters(), lr=1e-3, weight_decay=args.wd)\n",
        "criterion = loss_function_dae\n",
        "\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "best_r10 = -np.inf\n",
        "update_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0kLNpLo2f9A",
        "outputId": "437ce727-9ee0-4768-f44e-2e99dc4cb0b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 2.39s | valid loss 1016.38 | n100 0.259 | r10 0.197 | r20 0.191 | r50 0.247\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 2.50s | valid loss 980.87 | n100 0.318 | r10 0.255 | r20 0.236 | r50 0.287\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 2.52s | valid loss 965.73 | n100 0.348 | r10 0.286 | r20 0.262 | r50 0.316\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 2.47s | valid loss 955.18 | n100 0.372 | r10 0.309 | r20 0.284 | r50 0.337\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 2.51s | valid loss 947.30 | n100 0.387 | r10 0.323 | r20 0.294 | r50 0.351\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 2.54s | valid loss 942.99 | n100 0.393 | r10 0.327 | r20 0.299 | r50 0.357\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 2.52s | valid loss 939.22 | n100 0.400 | r10 0.333 | r20 0.306 | r50 0.364\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 2.49s | valid loss 935.93 | n100 0.406 | r10 0.337 | r20 0.310 | r50 0.370\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 2.52s | valid loss 933.16 | n100 0.411 | r10 0.344 | r20 0.316 | r50 0.375\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 2.54s | valid loss 930.89 | n100 0.417 | r10 0.350 | r20 0.322 | r50 0.381\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 2.49s | valid loss 928.66 | n100 0.419 | r10 0.350 | r20 0.323 | r50 0.384\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 2.49s | valid loss 926.97 | n100 0.421 | r10 0.350 | r20 0.322 | r50 0.387\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 2.46s | valid loss 925.20 | n100 0.425 | r10 0.360 | r20 0.329 | r50 0.390\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 2.43s | valid loss 923.75 | n100 0.429 | r10 0.364 | r20 0.333 | r50 0.392\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 2.45s | valid loss 922.45 | n100 0.431 | r10 0.363 | r20 0.335 | r50 0.395\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 2.47s | valid loss 920.94 | n100 0.432 | r10 0.365 | r20 0.336 | r50 0.397\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 2.52s | valid loss 920.17 | n100 0.431 | r10 0.357 | r20 0.331 | r50 0.397\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 2.50s | valid loss 918.56 | n100 0.433 | r10 0.361 | r20 0.334 | r50 0.400\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 2.51s | valid loss 917.24 | n100 0.437 | r10 0.371 | r20 0.341 | r50 0.403\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 2.46s | valid loss 916.01 | n100 0.440 | r10 0.371 | r20 0.342 | r50 0.404\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 2.44s | valid loss 914.85 | n100 0.441 | r10 0.373 | r20 0.343 | r50 0.404\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 2.44s | valid loss 913.87 | n100 0.441 | r10 0.373 | r20 0.345 | r50 0.405\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 2.53s | valid loss 912.94 | n100 0.442 | r10 0.374 | r20 0.345 | r50 0.407\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 2.50s | valid loss 911.79 | n100 0.441 | r10 0.368 | r20 0.342 | r50 0.407\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 2.51s | valid loss 910.99 | n100 0.444 | r10 0.376 | r20 0.345 | r50 0.409\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 2.50s | valid loss 910.23 | n100 0.440 | r10 0.363 | r20 0.340 | r50 0.408\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 2.50s | valid loss 909.41 | n100 0.444 | r10 0.374 | r20 0.347 | r50 0.410\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 2.54s | valid loss 908.49 | n100 0.445 | r10 0.374 | r20 0.346 | r50 0.410\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 2.47s | valid loss 907.93 | n100 0.447 | r10 0.379 | r20 0.349 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 2.46s | valid loss 906.92 | n100 0.446 | r10 0.378 | r20 0.349 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 2.47s | valid loss 906.30 | n100 0.447 | r10 0.378 | r20 0.349 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 2.46s | valid loss 905.64 | n100 0.447 | r10 0.379 | r20 0.350 | r50 0.414\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 2.46s | valid loss 904.78 | n100 0.446 | r10 0.377 | r20 0.348 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 2.48s | valid loss 904.37 | n100 0.448 | r10 0.378 | r20 0.350 | r50 0.414\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 2.54s | valid loss 903.56 | n100 0.445 | r10 0.372 | r20 0.346 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 2.52s | valid loss 903.21 | n100 0.448 | r10 0.379 | r20 0.349 | r50 0.414\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 2.52s | valid loss 902.62 | n100 0.445 | r10 0.371 | r20 0.346 | r50 0.411\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 2.55s | valid loss 902.02 | n100 0.446 | r10 0.373 | r20 0.345 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 2.50s | valid loss 901.91 | n100 0.439 | r10 0.353 | r20 0.335 | r50 0.408\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 2.47s | valid loss 900.79 | n100 0.446 | r10 0.370 | r20 0.346 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 2.50s | valid loss 900.25 | n100 0.447 | r10 0.375 | r20 0.349 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 2.49s | valid loss 900.05 | n100 0.443 | r10 0.363 | r20 0.341 | r50 0.411\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 2.53s | valid loss 899.42 | n100 0.447 | r10 0.377 | r20 0.349 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 2.51s | valid loss 899.30 | n100 0.450 | r10 0.383 | r20 0.352 | r50 0.414\n",
            "-----------------------------------------------------------------------------------------\n",
            "Better performance! save best model...\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 2.50s | valid loss 898.53 | n100 0.448 | r10 0.376 | r20 0.349 | r50 0.414\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 2.49s | valid loss 898.09 | n100 0.448 | r10 0.375 | r20 0.348 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 2.47s | valid loss 897.68 | n100 0.445 | r10 0.368 | r20 0.344 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 2.49s | valid loss 897.59 | n100 0.449 | r10 0.379 | r20 0.352 | r50 0.416\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 2.47s | valid loss 897.10 | n100 0.447 | r10 0.378 | r20 0.350 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 2.47s | valid loss 896.63 | n100 0.448 | r10 0.378 | r20 0.350 | r50 0.414\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 887.40 | n100 0.45 | r10 0.37 | r20 0.34 | r50 0.41\n",
            "=========================================================================================\n"
          ]
        }
      ],
      "source": [
        "############batch 1600\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "r10_fin_list = []\n",
        "new_epochs = 50\n",
        "\n",
        "for epoch in range(1, new_epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train(model, criterion, optimizer, is_VAE=False)\n",
        "    val_loss, n100, r10, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=False)\n",
        "    \n",
        "    train_loss_list.append(train_loss)\n",
        "    val_loss_list.append(val_loss)\n",
        "    r10_fin_list.append(r10)\n",
        "\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
        "            'n100 {:5.3f} | r10 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
        "                epoch, time.time() - epoch_start_time, val_loss,\n",
        "                n100, r10, r20, r50))\n",
        "    print('-' * 89)\n",
        "\n",
        "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
        "    \n",
        "    # Save the model if the n100 is the best we've seen so far.\n",
        "    if n100 > best_r10:\n",
        "        with open(args.save, 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_r10 = n100\n",
        "        print(\"Better performance! save best model...\")\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "\n",
        "# Run on test data.\n",
        "test_loss, n100, r10, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=False)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r10 {:4.2f} | r20 {:4.2f} | '\n",
        "        'r50 {:4.2f}'.format(test_loss, n100, r10, r20, r50))\n",
        "print('=' * 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "tiq3-LkR2qIh",
        "outputId": "9d2d8e0e-797b-4864-9db4-eb4d15743ba0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (loss_ax, recall_ax) = plt.subplots(1,2, figsize=(12,4))\n",
        "\n",
        "loss_ax.plot(range(1,new_epochs+1), train_loss_list, 'b', label='train loss')\n",
        "loss_ax.plot(range(1,new_epochs+1), val_loss_list, 'r', label='valid loss')\n",
        "recall_ax.plot(range(1,new_epochs+1), r10_fin_list, 'r', label='valid recall@10')\n",
        "\n",
        "loss_ax.set_xticks(range(0, new_epochs+1, 10))\n",
        "loss_ax.set_xlabel('Epoch')\n",
        "loss_ax.set_ylabel('Average Loss')\n",
        "loss_ax.legend()\n",
        "\n",
        "recall_ax.set_xticks(range(0, new_epochs+1, 10))\n",
        "recall_ax.set_xlabel('Epoch')\n",
        "recall_ax.set_ylabel('Recall@10')\n",
        "recall_ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference(BERT4Rec과 Ensemble)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98SbUnXr2_ke",
        "outputId": "81e3d5db-5d9c-43df-d160-09000b8de1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.shape :  (31360, 6807)\n",
            "(31360, 10)\n"
          ]
        }
      ],
      "source": [
        "## 배치사이즈 포함\n",
        "def numerize_for_infer(tp, profile2id, show2id):\n",
        "    uid = tp['user'].apply(lambda x: profile2id[x])\n",
        "    sid = tp['item'].apply(lambda x: show2id[x])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])\n",
        "\n",
        "### 데이터 준비    \n",
        "infer_df = numerize_for_infer(raw_data, profile2id, show2id)\n",
        "\n",
        "loader = DataLoader(args.data)\n",
        "n_items = loader.load_n_items()\n",
        "\n",
        "n_users = infer_df['uid'].max() + 1\n",
        "\n",
        "rows, cols = infer_df['uid'], infer_df['sid']\n",
        "data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                                 (rows, cols)), dtype='float64',\n",
        "                                 shape=(n_users, n_items))\n",
        "print(\"data.shape : \", data.shape)\n",
        "N = data.shape[0]\n",
        "idxlist = list(range(N))\n",
        "\n",
        "model.eval()\n",
        "total_loss = 0.0\n",
        "e_idxlist = list(range(data.shape[0]))\n",
        "e_N = data.shape[0]\n",
        "pred_list = None\n",
        "\n",
        "with torch.no_grad():\n",
        "    for start_idx in range(0, e_N, args.batch_size):\n",
        "        end_idx = min(start_idx + args.batch_size, N)\n",
        "        data_batch = data[e_idxlist[start_idx:end_idx]]\n",
        "\n",
        "        data_tensor = naive_sparse2tensor(data_batch).to(device)\n",
        "\n",
        "        recon_batch = model(data_tensor)\n",
        "        loss = criterion(recon_batch, data_tensor)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Exclude examples from training set\n",
        "        recon_batch = recon_batch.cpu().numpy()\n",
        "        recon_batch[data_batch.nonzero()] = -np.inf\n",
        "  \n",
        "        ##Recall\n",
        "        batch_users = recon_batch.shape[0]\n",
        "        recon_batch += Bert_recon[start_idx:end_idx, 1:]*0.5 #BERT4Rec과 Ensemble\n",
        "\n",
        "        idx = bn.argpartition(-recon_batch, 10, axis=1)[:, :10]\n",
        "        if start_idx == 0:\n",
        "            pred_list = idx\n",
        "        else:\n",
        "            pred_list = np.append(pred_list, idx, axis=0)\n",
        "        #print(recon_batch.shape)\n",
        "        #print(pred_list.shape)\n",
        "\n",
        "#print(recon_batch.shape)\n",
        "print(pred_list.shape)\n",
        "\n",
        "## sample_submission에 맞게끔 바꾸기\n",
        "user2 = []\n",
        "item2 = []\n",
        "for i_idx, arr_10 in enumerate(pred_list):\n",
        "    user2.extend([i_idx]*10)\n",
        "    item2.extend(arr_10)\n",
        "\n",
        "u2 = pd.DataFrame(user2, columns=['user'])\n",
        "i2 = pd.DataFrame(item2, columns=['item'])\n",
        "all2 = pd.concat([u2, i2], axis=1)\n",
        "\n",
        "re_p2id = dict((v, k) for k, v in profile2id.items())\n",
        "re_s2id = dict((v, k) for k, v in show2id.items())\n",
        "\n",
        "def de_numerize(tp, re_p2id, re_s2id):\n",
        "    uid2 = tp['user'].apply(lambda x: re_p2id[x])\n",
        "    sid2 = tp['item'].apply(lambda x: re_s2id[x])\n",
        "    return pd.DataFrame(data={'uid': uid2, 'sid': sid2}, columns=['uid', 'sid'])\n",
        "\n",
        "ans2 = de_numerize(all2, re_p2id, re_s2id)\n",
        "ans2.columns = ['user', 'item']\n",
        "new_ans2 = ans2.sort_values('user')\n",
        "\n",
        "### 확인용\n",
        "submit_data = pd.read_csv('/opt/ml/input/code/data/eval/sample_submission.csv', sep='\\t')\n",
        "sum(new_ans2.user.values == submit_data.user.values)\n",
        "new_ans2.reset_index(drop=True, inplace=True)\n",
        "new_ans2.to_csv('/opt/ml/input/code/output/answer/0330_submit_multi_dae.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5aeb186a90>]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "temp = pd.read_csv('/opt/ml/input/code/output/answer/0330_submit_multi_dae.csv')\n",
        "plt.plot(temp['item'].value_counts().values)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Mission2_Multi-VAE-정답.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
