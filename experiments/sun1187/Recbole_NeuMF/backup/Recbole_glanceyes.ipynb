{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from recbole.quick_start import run_recbole\n",
    "from tqdm import tqdm\n",
    "#!pip install recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/opt/ml/input/data/train\"\n",
    "output_path = \"/opt/ml/input/data/recbole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie = pd.read_csv(os.path.join(dataset_path, 'train_ratings.csv'))\n",
    "movie['rating'] = [1] * len(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           user   item        time  rating\n",
      "0            11   4643  1230782529       1\n",
      "1            11    170  1230782534       1\n",
      "2            11    531  1230782539       1\n",
      "3            11    616  1230782542       1\n",
      "4            11   2140  1230782563       1\n",
      "...         ...    ...         ...     ...\n",
      "5154466  138493  44022  1260209449       1\n",
      "5154467  138493   4958  1260209482       1\n",
      "5154468  138493  68319  1260209720       1\n",
      "5154469  138493  40819  1260209726       1\n",
      "5154470  138493  27311  1260209807       1\n",
      "\n",
      "[5154471 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.item.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie.columns = ['user', 'item', 'timestamp', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1230782534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1230782539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1230782542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1230782563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "      <td>1260209449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "      <td>1260209482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>1260209720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "      <td>1260209726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "      <td>1260209807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154471 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item   timestamp  rating\n",
       "0            11   4643  1230782529       1\n",
       "1            11    170  1230782534       1\n",
       "2            11    531  1230782539       1\n",
       "3            11    616  1230782542       1\n",
       "4            11   2140  1230782563       1\n",
       "...         ...    ...         ...     ...\n",
       "5154466  138493  44022  1260209449       1\n",
       "5154467  138493   4958  1260209482       1\n",
       "5154468  138493  68319  1260209720       1\n",
       "5154469  138493  40819  1260209726       1\n",
       "5154470  138493  27311  1260209807       1\n",
       "\n",
       "[5154471 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie = movie[['user', 'item', 'rating', 'timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1</td>\n",
       "      <td>1230782529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1230782534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1</td>\n",
       "      <td>1230782539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "      <td>1230782542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1</td>\n",
       "      <td>1230782563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "      <td>1</td>\n",
       "      <td>1260209449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "      <td>1</td>\n",
       "      <td>1260209482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>1</td>\n",
       "      <td>1260209720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "      <td>1</td>\n",
       "      <td>1260209726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "      <td>1</td>\n",
       "      <td>1260209807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154471 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item  rating   timestamp\n",
       "0            11   4643       1  1230782529\n",
       "1            11    170       1  1230782534\n",
       "2            11    531       1  1230782539\n",
       "3            11    616       1  1230782542\n",
       "4            11   2140       1  1230782563\n",
       "...         ...    ...     ...         ...\n",
       "5154466  138493  44022       1  1260209449\n",
       "5154467  138493   4958       1  1260209482\n",
       "5154468  138493  68319       1  1260209720\n",
       "5154469  138493  40819       1  1260209726\n",
       "5154470  138493  27311       1  1260209807\n",
       "\n",
       "[5154471 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie.to_csv(os.path.join(dataset_path, 'rating.csv'), header=True, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie['user'].to_csv(os.path.join(dataset_path, 'user.csv'), header=True, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie['item'].to_csv(os.path.join(dataset_path, 'item.csv'), header=True, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaseDataset(object):\n",
    "    def __init__(self, input_path, output_path):\n",
    "        super(BaseDataset, self).__init__()\n",
    "\n",
    "        self.dataset_name = ''\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.check_output_path()\n",
    "\n",
    "        # input file\n",
    "        self.inter_file = os.path.join(self.input_path, \"rating.csv\")\n",
    "        self.user_file = os.path.join(self.input_path, \"user.csv\")\n",
    "        self.item_file = os.path.join(self.input_path, \"item.csv\")\n",
    "        self.sep = '\\t'\n",
    "\n",
    "        # output file\n",
    "        self.output_inter_file, self.output_item_file, self.output_user_file = self.get_output_files()\n",
    "\n",
    "        # selected feature fields\n",
    "        self.inter_fields = {}\n",
    "        self.item_fields = {}\n",
    "        self.user_fields = {}\n",
    "\n",
    "    def check_output_path(self):\n",
    "        if not os.path.isdir(self.output_path):\n",
    "            os.makedirs(self.output_path)\n",
    "\n",
    "    def get_output_files(self):\n",
    "        output_inter_file = os.path.join(self.output_path, self.dataset_name + '.inter')\n",
    "        output_item_file = os.path.join(self.output_path, self.dataset_name + '.item')\n",
    "        output_user_file = os.path.join(self.output_path, self.dataset_name + '.user')\n",
    "        return output_inter_file, output_item_file, output_user_file\n",
    "\n",
    "    def load_inter_data(self) -> pd.DataFrame():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load_item_data(self) -> pd.DataFrame():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load_user_data(self) -> pd.DataFrame():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_inter(self):\n",
    "        try:\n",
    "            input_inter_data = self.load_inter_data()\n",
    "            self.convert(input_inter_data, self.inter_fields, self.output_inter_file)\n",
    "        except NotImplementedError:\n",
    "            print('This dataset can\\'t be converted to inter file\\n')\n",
    "\n",
    "    def convert_item(self):\n",
    "        try:\n",
    "            input_item_data = self.load_item_data()\n",
    "            self.convert(input_item_data, self.item_fields, self.output_item_file)\n",
    "        except NotImplementedError:\n",
    "            print('This dataset can\\'t be converted to item file\\n')\n",
    "\n",
    "    def convert_user(self):\n",
    "        try:\n",
    "            input_user_data = self.load_user_data()\n",
    "            self.convert(input_user_data, self.user_fields, self.output_user_file)\n",
    "        except NotImplementedError:\n",
    "            print('This dataset can\\'t be converted to user file\\n')\n",
    "\n",
    "    @staticmethod\n",
    "    def convert(input_data, selected_fields, output_file):\n",
    "        output_data = pd.DataFrame()\n",
    "        for column in selected_fields:\n",
    "            output_data[column] = input_data.iloc[:, column]\n",
    "        with open(output_file, 'w') as fp:\n",
    "            fp.write('\\t'.join([selected_fields[column] for column in output_data.columns]) + '\\n')\n",
    "            for i in tqdm(range(output_data.shape[0])):\n",
    "                fp.write('\\t'.join([str(output_data.iloc[i, j])\n",
    "                                    for j in range(output_data.shape[1])]) + '\\n')\n",
    "\n",
    "    def parse_json(self, data_path):\n",
    "        with open(data_path, 'rb') as g:\n",
    "            for l in g:\n",
    "                yield eval(l)\n",
    "\n",
    "    def getDF(self, data_path):\n",
    "        i = 0\n",
    "        df = {}\n",
    "        for d in self.parse_json(data_path):\n",
    "            df[i] = d\n",
    "            i += 1\n",
    "        data = pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MovieDataset(BaseDataset):\n",
    "    def __init__(self, input_path, output_path):\n",
    "        super(MovieDataset, self).__init__(input_path, output_path)\n",
    "        self.dataset_name = \"recbole\"\n",
    "\n",
    "        self.inter_file = os.path.join(self.input_path, \"rating.csv\")\n",
    "        self.item_file = os.path.join(self.input_path, \"user.csv\")\n",
    "        self.user_file = os.path.join(self.input_path, \"item.csv\")\n",
    "\n",
    "        self.sep = \",\"\n",
    "\n",
    "        # output_path\n",
    "        output_files = self.get_output_files()\n",
    "        self.output_inter_file = output_files[0]\n",
    "        self.output_item_file = output_files[1]\n",
    "        self.output_user_file = output_files[2]\n",
    "\n",
    "        # selected feature fields\n",
    "        self.inter_fields = {\n",
    "            0: \"user:token\",\n",
    "            1: \"item:token\",\n",
    "            2: \"rating:float\",\n",
    "            3: \"timestamp:float\",\n",
    "        }\n",
    "\n",
    "        self.item_fields = {\n",
    "            0: \"user:token\",\n",
    "        }\n",
    "\n",
    "        self.user_fields = {\n",
    "            0: \"item:token\",\n",
    "        }\n",
    "\n",
    "    def load_inter_data(self):\n",
    "        df = pd.read_csv(self.inter_file,\n",
    "            dtype={\"user\": int, \"item\": int, \"rating\": float, \"timestamp\":float}\n",
    "           )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def load_item_data(self):\n",
    "        return pd.read_csv(self.item_file, delimiter=self.sep, engine=\"python\")\n",
    "\n",
    "    def load_user_data(self):\n",
    "        return pd.read_csv(self.user_file, delimiter=self.sep, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movieDataset = MovieDataset(dataset_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5154471/5154471 [08:38<00:00, 9940.64it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5154471/5154471 [02:24<00:00, 35599.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5154471/5154471 [02:24<00:00, 35731.42it/s]\n"
     ]
    }
   ],
   "source": [
    "movieDataset.convert_inter()\n",
    "movieDataset.convert_user()\n",
    "movieDataset.convert_item()\n",
    "del movieDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cfg_str = \"\"\"\n",
    "data_path: /opt/ml/input/data/\n",
    "dataset: recbole\n",
    "field_separator: \"\\\\t\"\n",
    "USER_ID_FIELD: user\n",
    "ITEM_ID_FIELD: item\n",
    "RATING_FIELD: rating\n",
    "TIME_FIELD: timestamp\n",
    "show_progress: false\n",
    "\n",
    "load_col:\n",
    "    inter: [user, item, rating, timestamp]\n",
    "    user: [user]\n",
    "    item: [item]\n",
    "\n",
    "epochs: 5\n",
    "learning_rate: 0.01\n",
    "user_inter_num_interval: \"[0,inf)\"\n",
    "item_inter_num_interval: \"[0,inf)\"\n",
    "filter_inter_by_user_or_item: false\n",
    "neg_sampling:\n",
    "    uniform: 1\n",
    "eval_args:\n",
    "    split: {'RS': [4, 1, 1]}\n",
    "    group_by: user\n",
    "    order: TO\n",
    "    mode: uni50\n",
    "metrics: ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
    "topk: 10\n",
    "valid_metric: Recall@10\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(os.path.join(output_path, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run(model_name):\n",
    "    if model_name in [\n",
    "        \"MultiVAE\",\n",
    "        \"MultiDAE\",\n",
    "        \"MacridVAE\",\n",
    "        \"RecVAE\",\n",
    "        \"GRU4Rec\",\n",
    "        \"NARM\",\n",
    "        \"SASRecF\",\n",
    "        \"STAMP\",\n",
    "        \"NextItNet\",\n",
    "        \"TransRec\",\n",
    "        \"SASRec\",\n",
    "        \"BERT4Rec\",\n",
    "        \"SRGNN\",\n",
    "        \"GCSAN\",\n",
    "        \"GRU4RecF\",\n",
    "        \"FOSSIL\",\n",
    "        \"SHAN\",\n",
    "        \"RepeatNet\",\n",
    "        \"HRM\",\n",
    "        \"NPE\",\n",
    "    ]:\n",
    "        parameter_dict = {\n",
    "            \"neg_sampling\": None,\n",
    "        }\n",
    "        return run_recbole(\n",
    "            model=model_name,\n",
    "            dataset='recbole',\n",
    "            config_file_list=['/opt/ml/input/data/recbole/config.yaml'],\n",
    "            config_dict=parameter_dict,\n",
    "        )\n",
    "    else:\n",
    "        return run_recbole(\n",
    "            model=model_name,\n",
    "            dataset='recbole',\n",
    "            config_file_list=['/opt/ml/input/data/recbole/config.yaml'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì¶”ê°€\n",
    "#%%time\n",
    "model_list = [\"Pop\", \"ItemKNN\", \"BPR\", \"NeuMF\", \"RecVAE\", \"LightGCN\"] # General\n",
    "model_list += [\"FFM\", \"DeepFM\"] # Context-aware\n",
    "model_list += [\"GRU4Rec\", \"SHAN\"] # Sequential\n",
    "\n",
    "model_name = \"NeuMF\"\n",
    "print(f\"running {model_name}...\")\n",
    "start = time.time()\n",
    "result = run(model_name)\n",
    "t = time.time() - start\n",
    "print(f\"It took {t/60:.2f} mins\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Pop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 04:53    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/input/data/recbole\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.01\n",
      "neg_sampling = {'uniform': 1}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user\n",
      "ITEM_ID_FIELD = item\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user', 'item', 'rating', 'timestamp'], 'user': ['user'], 'item': ['item']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "MODEL_TYPE = ModelType.TRADITIONAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 1, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'by', 'by': 50, 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "14 Apr 04:53    WARNING  No columns has been loaded from [FeatureSource.USER]\n",
      "14 Apr 04:53    WARNING  No columns has been loaded from [FeatureSource.ITEM]\n",
      "14 Apr 04:53    INFO  recbole\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user', 'item', 'rating', 'timestamp']\n",
      "14 Apr 04:53    INFO  [Training]: train_batch_size = [2048] negative sampling: [{'uniform': 1}]\n",
      "14 Apr 04:53    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}]\n",
      "14 Apr 04:53    INFO  Pop()\n",
      "Trainable parameters: 1\n",
      "14 Apr 04:53    INFO  epoch 0 training [time: 4.05s, train loss: 0.0000]\n",
      "14 Apr 04:54    INFO  epoch 0 evaluating [time: 51.85s, valid_score: 0.192800]\n",
      "14 Apr 04:54    INFO  valid result: \n",
      "recall@10 : 0.1928    mrr@10 : 0.4927    ndcg@10 : 0.3164    hit@10 : 0.8403    precision@10 : 0.3002    map@10 : 0.1927\n",
      "14 Apr 04:54    INFO  Saving current: saved/Pop-Apr-14-2022_04-53-41.pth\n",
      "14 Apr 04:54    INFO  Loading model structure and parameters from saved/Pop-Apr-14-2022_04-53-41.pth\n",
      "14 Apr 04:55    INFO  best valid : OrderedDict([('recall@10', 0.1928), ('mrr@10', 0.4927), ('ndcg@10', 0.3164), ('hit@10', 0.8403), ('precision@10', 0.3002), ('map@10', 0.1927)])\n",
      "14 Apr 04:55    INFO  test result: OrderedDict([('recall@10', 0.173), ('mrr@10', 0.4649), ('ndcg@10', 0.2851), ('hit@10', 0.8192), ('precision@10', 0.269), ('map@10', 0.1672)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 2.44 mins\n",
      "{'best_valid_score': 0.1928, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.1928), ('mrr@10', 0.4927), ('ndcg@10', 0.3164), ('hit@10', 0.8403), ('precision@10', 0.3002), ('map@10', 0.1927)]), 'test_result': OrderedDict([('recall@10', 0.173), ('mrr@10', 0.4649), ('ndcg@10', 0.2851), ('hit@10', 0.8192), ('precision@10', 0.269), ('map@10', 0.1672)])}\n",
      "running ItemKNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 04:55    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/input/data/recbole\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.01\n",
      "neg_sampling = {'uniform': 1}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user\n",
      "ITEM_ID_FIELD = item\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user', 'item', 'rating', 'timestamp'], 'user': ['user'], 'item': ['item']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "k = 100\n",
      "shrink = 0.0\n",
      "MODEL_TYPE = ModelType.TRADITIONAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 1, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'by', 'by': 50, 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "14 Apr 04:55    WARNING  No columns has been loaded from [FeatureSource.USER]\n",
      "14 Apr 04:55    WARNING  No columns has been loaded from [FeatureSource.ITEM]\n",
      "14 Apr 04:55    INFO  recbole\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user', 'item', 'rating', 'timestamp']\n",
      "14 Apr 04:56    INFO  [Training]: train_batch_size = [2048] negative sampling: [{'uniform': 1}]\n",
      "14 Apr 04:56    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}]\n",
      "14 Apr 04:56    INFO  ItemKNN()\n",
      "Trainable parameters: 1\n",
      "14 Apr 04:56    INFO  epoch 0 training [time: 3.77s, train loss: 0.0000]\n",
      "14 Apr 05:00    INFO  epoch 0 evaluating [time: 228.52s, valid_score: 0.232100]\n",
      "14 Apr 05:00    INFO  valid result: \n",
      "recall@10 : 0.2321    mrr@10 : 0.5739    ndcg@10 : 0.3821    hit@10 : 0.9045    precision@10 : 0.3599    map@10 : 0.2442\n",
      "14 Apr 05:01    INFO  Saving current: saved/ItemKNN-Apr-14-2022_04-56-39.pth\n",
      "14 Apr 05:02    INFO  Loading model structure and parameters from saved/ItemKNN-Apr-14-2022_04-56-39.pth\n",
      "14 Apr 05:06    INFO  best valid : OrderedDict([('recall@10', 0.2321), ('mrr@10', 0.5739), ('ndcg@10', 0.3821), ('hit@10', 0.9045), ('precision@10', 0.3599), ('map@10', 0.2442)])\n",
      "14 Apr 05:06    INFO  test result: OrderedDict([('recall@10', 0.1982), ('mrr@10', 0.5249), ('ndcg@10', 0.3272), ('hit@10', 0.8689), ('precision@10', 0.3059), ('map@10', 0.1977)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 10.85 mins\n",
      "{'best_valid_score': 0.2321, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.2321), ('mrr@10', 0.5739), ('ndcg@10', 0.3821), ('hit@10', 0.9045), ('precision@10', 0.3599), ('map@10', 0.2442)]), 'test_result': OrderedDict([('recall@10', 0.1982), ('mrr@10', 0.5249), ('ndcg@10', 0.3272), ('hit@10', 0.8689), ('precision@10', 0.3059), ('map@10', 0.1977)])}\n",
      "running BPR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 05:06    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/input/data/recbole\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.01\n",
      "neg_sampling = {'uniform': 1}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user\n",
      "ITEM_ID_FIELD = item\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user', 'item', 'rating', 'timestamp'], 'user': ['user'], 'item': ['item']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 1, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'by', 'by': 50, 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "14 Apr 05:06    WARNING  No columns has been loaded from [FeatureSource.USER]\n",
      "14 Apr 05:06    WARNING  No columns has been loaded from [FeatureSource.ITEM]\n",
      "14 Apr 05:06    INFO  recbole\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user', 'item', 'rating', 'timestamp']\n",
      "14 Apr 05:07    INFO  [Training]: train_batch_size = [2048] negative sampling: [{'uniform': 1}]\n",
      "14 Apr 05:07    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}]\n",
      "14 Apr 05:07    INFO  BPR(\n",
      "  (user_embedding): Embedding(31361, 64)\n",
      "  (item_embedding): Embedding(6808, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 2442816\n",
      "14 Apr 05:07    INFO  epoch 0 training [time: 4.35s, train loss: 440.8769]\n",
      "14 Apr 05:08    INFO  epoch 0 evaluating [time: 63.90s, valid_score: 0.197500]\n",
      "14 Apr 05:08    INFO  valid result: \n",
      "recall@10 : 0.1975    mrr@10 : 0.5432    ndcg@10 : 0.3341    hit@10 : 0.9008    precision@10 : 0.3128    map@10 : 0.1976\n",
      "14 Apr 05:08    INFO  Saving current: saved/BPR-Apr-14-2022_05-07-01.pth\n",
      "14 Apr 05:08    INFO  epoch 1 training [time: 4.38s, train loss: 304.8810]\n",
      "14 Apr 05:09    INFO  epoch 1 evaluating [time: 50.82s, valid_score: 0.197600]\n",
      "14 Apr 05:09    INFO  valid result: \n",
      "recall@10 : 0.1976    mrr@10 : 0.5463    ndcg@10 : 0.3342    hit@10 : 0.9076    precision@10 : 0.3132    map@10 : 0.1961\n",
      "14 Apr 05:09    INFO  Saving current: saved/BPR-Apr-14-2022_05-07-01.pth\n",
      "14 Apr 05:09    INFO  epoch 2 training [time: 4.49s, train loss: 282.8294]\n",
      "14 Apr 05:09    INFO  epoch 2 evaluating [time: 49.23s, valid_score: 0.195900]\n",
      "14 Apr 05:09    INFO  valid result: \n",
      "recall@10 : 0.1959    mrr@10 : 0.5436    ndcg@10 : 0.3311    hit@10 : 0.9076    precision@10 : 0.3102    map@10 : 0.1932\n",
      "14 Apr 05:10    INFO  epoch 3 training [time: 4.41s, train loss: 273.9558]\n",
      "14 Apr 05:10    INFO  epoch 3 evaluating [time: 53.13s, valid_score: 0.195400]\n",
      "14 Apr 05:10    INFO  valid result: \n",
      "recall@10 : 0.1954    mrr@10 : 0.5468    ndcg@10 : 0.3301    hit@10 : 0.9123    precision@10 : 0.3085    map@10 : 0.1915\n",
      "14 Apr 05:11    INFO  epoch 4 training [time: 4.52s, train loss: 269.6512]\n",
      "14 Apr 05:11    INFO  epoch 4 evaluating [time: 53.77s, valid_score: 0.193600]\n",
      "14 Apr 05:11    INFO  valid result: \n",
      "recall@10 : 0.1936    mrr@10 : 0.5399    ndcg@10 : 0.3264    hit@10 : 0.9137    precision@10 : 0.3066    map@10 : 0.188\n",
      "14 Apr 05:11    INFO  Loading model structure and parameters from saved/BPR-Apr-14-2022_05-07-01.pth\n",
      "14 Apr 05:12    INFO  best valid : OrderedDict([('recall@10', 0.1976), ('mrr@10', 0.5463), ('ndcg@10', 0.3342), ('hit@10', 0.9076), ('precision@10', 0.3132), ('map@10', 0.1961)])\n",
      "14 Apr 05:12    INFO  test result: OrderedDict([('recall@10', 0.1743), ('mrr@10', 0.5056), ('ndcg@10', 0.2937), ('hit@10', 0.8748), ('precision@10', 0.2734), ('map@10', 0.1648)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 6.50 mins\n",
      "{'best_valid_score': 0.1976, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.1976), ('mrr@10', 0.5463), ('ndcg@10', 0.3342), ('hit@10', 0.9076), ('precision@10', 0.3132), ('map@10', 0.1961)]), 'test_result': OrderedDict([('recall@10', 0.1743), ('mrr@10', 0.5056), ('ndcg@10', 0.2937), ('hit@10', 0.8748), ('precision@10', 0.2734), ('map@10', 0.1648)])}\n",
      "running NeuMF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 05:12    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/input/data/recbole\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.01\n",
      "neg_sampling = {'uniform': 1}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user\n",
      "ITEM_ID_FIELD = item\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user', 'item', 'rating', 'timestamp'], 'user': ['user'], 'item': ['item']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "mf_embedding_size = 64\n",
      "mlp_embedding_size = 64\n",
      "mlp_hidden_size = [128, 64]\n",
      "dropout_prob = 0.1\n",
      "mf_train = True\n",
      "mlp_train = True\n",
      "use_pretrain = False\n",
      "mf_pretrain_path = None\n",
      "mlp_pretrain_path = None\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 1, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'by', 'by': 50, 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "14 Apr 05:13    WARNING  No columns has been loaded from [FeatureSource.USER]\n",
      "14 Apr 05:13    WARNING  No columns has been loaded from [FeatureSource.ITEM]\n",
      "14 Apr 05:13    INFO  recbole\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user', 'item', 'rating', 'timestamp']\n",
      "14 Apr 05:13    INFO  [Training]: train_batch_size = [2048] negative sampling: [{'uniform': 1}]\n",
      "14 Apr 05:13    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}]\n",
      "14 Apr 05:13    INFO  NeuMF(\n",
      "  (user_mf_embedding): Embedding(31361, 64)\n",
      "  (item_mf_embedding): Embedding(6808, 64)\n",
      "  (user_mlp_embedding): Embedding(31361, 64)\n",
      "  (item_mlp_embedding): Embedding(6808, 64)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCELoss()\n",
      ")\n",
      "Trainable parameters: 4910529\n",
      "14 Apr 05:13    INFO  epoch 0 training [time: 11.88s, train loss: 1235.9514]\n",
      "14 Apr 05:14    INFO  epoch 0 evaluating [time: 59.24s, valid_score: 0.216300]\n",
      "14 Apr 05:14    INFO  valid result: \n",
      "recall@10 : 0.2163    mrr@10 : 0.5704    ndcg@10 : 0.3645    hit@10 : 0.9117    precision@10 : 0.3419    map@10 : 0.2239\n",
      "14 Apr 05:14    INFO  Saving current: saved/NeuMF-Apr-14-2022_05-13-28.pth\n",
      "14 Apr 05:14    INFO  epoch 1 training [time: 11.83s, train loss: 1011.1219]\n",
      "14 Apr 05:15    INFO  epoch 1 evaluating [time: 60.72s, valid_score: 0.220000]\n",
      "14 Apr 05:15    INFO  valid result: \n",
      "recall@10 : 0.22    mrr@10 : 0.589    ndcg@10 : 0.3728    hit@10 : 0.9267    precision@10 : 0.3482    map@10 : 0.2277\n",
      "14 Apr 05:15    INFO  Saving current: saved/NeuMF-Apr-14-2022_05-13-28.pth\n",
      "14 Apr 05:16    INFO  epoch 2 training [time: 11.39s, train loss: 923.6780]\n",
      "14 Apr 05:17    INFO  epoch 2 evaluating [time: 61.54s, valid_score: 0.228600]\n",
      "14 Apr 05:17    INFO  valid result: \n",
      "recall@10 : 0.2286    mrr@10 : 0.5937    ndcg@10 : 0.3851    hit@10 : 0.9246    precision@10 : 0.3609    map@10 : 0.2409\n",
      "14 Apr 05:17    INFO  Saving current: saved/NeuMF-Apr-14-2022_05-13-28.pth\n",
      "14 Apr 05:17    INFO  epoch 3 training [time: 11.65s, train loss: 858.1393]\n",
      "14 Apr 05:18    INFO  epoch 3 evaluating [time: 62.39s, valid_score: 0.227600]\n",
      "14 Apr 05:18    INFO  valid result: \n",
      "recall@10 : 0.2276    mrr@10 : 0.595    ndcg@10 : 0.3835    hit@10 : 0.9298    precision@10 : 0.3595    map@10 : 0.2384\n",
      "14 Apr 05:18    INFO  epoch 4 training [time: 12.10s, train loss: 804.4745]\n",
      "14 Apr 05:19    INFO  epoch 4 evaluating [time: 62.66s, valid_score: 0.217900]\n",
      "14 Apr 05:19    INFO  valid result: \n",
      "recall@10 : 0.2179    mrr@10 : 0.5834    ndcg@10 : 0.3677    hit@10 : 0.9342    precision@10 : 0.3449    map@10 : 0.2219\n",
      "14 Apr 05:19    INFO  Loading model structure and parameters from saved/NeuMF-Apr-14-2022_05-13-28.pth\n",
      "14 Apr 05:20    INFO  best valid : OrderedDict([('recall@10', 0.2286), ('mrr@10', 0.5937), ('ndcg@10', 0.3851), ('hit@10', 0.9246), ('precision@10', 0.3609), ('map@10', 0.2409)])\n",
      "14 Apr 05:20    INFO  test result: OrderedDict([('recall@10', 0.2007), ('mrr@10', 0.5466), ('ndcg@10', 0.3366), ('hit@10', 0.8938), ('precision@10', 0.3138), ('map@10', 0.2008)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 7.80 mins\n",
      "{'best_valid_score': 0.2286, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.2286), ('mrr@10', 0.5937), ('ndcg@10', 0.3851), ('hit@10', 0.9246), ('precision@10', 0.3609), ('map@10', 0.2409)]), 'test_result': OrderedDict([('recall@10', 0.2007), ('mrr@10', 0.5466), ('ndcg@10', 0.3366), ('hit@10', 0.8938), ('precision@10', 0.3138), ('map@10', 0.2008)])}\n",
      "running RecVAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 05:20    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/input/data/recbole\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.01\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user\n",
      "ITEM_ID_FIELD = item\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user', 'item', 'rating', 'timestamp'], 'user': ['user'], 'item': ['item']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "hidden_dimension = 600\n",
      "latent_dimension = 200\n",
      "dropout_prob = 0.5\n",
      "beta = 0.2\n",
      "mixture_weights = [0.15, 0.75, 0.1]\n",
      "gamma = 0.005\n",
      "n_enc_epochs = 3\n",
      "n_dec_epochs = 1\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'by', 'by': 50, 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "14 Apr 05:21    WARNING  No columns has been loaded from [FeatureSource.USER]\n",
      "14 Apr 05:21    WARNING  No columns has been loaded from [FeatureSource.ITEM]\n",
      "14 Apr 05:21    INFO  recbole\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user', 'item', 'rating', 'timestamp']\n",
      "14 Apr 05:21    INFO  [Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "14 Apr 05:21    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}]\n",
      "14 Apr 05:21    WARNING  Max value of user's history interaction records has reached 28.525264394829613% of the total.\n",
      "14 Apr 05:21    INFO  RecVAE(\n",
      "  (encoder): Encoder(\n",
      "    (fc1): Linear(in_features=6808, out_features=600, bias=True)\n",
      "    (ln1): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (ln2): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "    (fc3): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (ln3): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "    (fc4): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (ln4): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "    (fc5): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (ln5): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "    (fc_mu): Linear(in_features=600, out_features=200, bias=True)\n",
      "    (fc_logvar): Linear(in_features=600, out_features=200, bias=True)\n",
      "  )\n",
      "  (prior): CompositePrior(\n",
      "    (encoder_old): Encoder(\n",
      "      (fc1): Linear(in_features=6808, out_features=600, bias=True)\n",
      "      (ln1): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "      (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
      "      (ln2): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "      (fc3): Linear(in_features=600, out_features=600, bias=True)\n",
      "      (ln3): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "      (fc4): Linear(in_features=600, out_features=600, bias=True)\n",
      "      (ln4): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "      (fc5): Linear(in_features=600, out_features=600, bias=True)\n",
      "      (ln5): LayerNorm((600,), eps=0.1, elementwise_affine=True)\n",
      "      (fc_mu): Linear(in_features=600, out_features=200, bias=True)\n",
      "      (fc_logvar): Linear(in_features=600, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=200, out_features=6808, bias=True)\n",
      ")\n",
      "Trainable parameters: 7142608\n",
      "14 Apr 05:21    INFO  epoch 0 training [time: 1.01s, train loss: 9889.9264]\n",
      "14 Apr 05:23    INFO  epoch 0 evaluating [time: 143.85s, valid_score: 0.192500]\n",
      "14 Apr 05:23    INFO  valid result: \n",
      "recall@10 : 0.1925    mrr@10 : 0.4908    ndcg@10 : 0.3158    hit@10 : 0.8414    precision@10 : 0.3001    map@10 : 0.1922\n",
      "14 Apr 05:23    INFO  Saving current: saved/RecVAE-Apr-14-2022_05-21-23.pth\n",
      "14 Apr 05:23    INFO  epoch 1 training [time: 0.95s, train loss: 9589.7905]\n",
      "14 Apr 05:26    INFO  epoch 1 evaluating [time: 145.61s, valid_score: 0.192700]\n",
      "14 Apr 05:26    INFO  valid result: \n",
      "recall@10 : 0.1927    mrr@10 : 0.49    ndcg@10 : 0.3153    hit@10 : 0.8417    precision@10 : 0.2997    map@10 : 0.1919\n",
      "14 Apr 05:26    INFO  Saving current: saved/RecVAE-Apr-14-2022_05-21-23.pth\n",
      "14 Apr 05:26    INFO  epoch 2 training [time: 0.95s, train loss: 9395.4395]\n",
      "14 Apr 05:28    INFO  epoch 2 evaluating [time: 157.66s, valid_score: 0.192900]\n",
      "14 Apr 05:28    INFO  valid result: \n",
      "recall@10 : 0.1929    mrr@10 : 0.4935    ndcg@10 : 0.317    hit@10 : 0.8463    precision@10 : 0.3009    map@10 : 0.193\n",
      "14 Apr 05:28    INFO  Saving current: saved/RecVAE-Apr-14-2022_05-21-23.pth\n",
      "14 Apr 05:28    INFO  epoch 3 training [time: 0.95s, train loss: 9292.7893]\n",
      "14 Apr 05:31    INFO  epoch 3 evaluating [time: 154.23s, valid_score: 0.194000]\n",
      "14 Apr 05:31    INFO  valid result: \n",
      "recall@10 : 0.194    mrr@10 : 0.5031    ndcg@10 : 0.3204    hit@10 : 0.8517    precision@10 : 0.3029    map@10 : 0.1949\n",
      "14 Apr 05:31    INFO  Saving current: saved/RecVAE-Apr-14-2022_05-21-23.pth\n",
      "14 Apr 05:31    INFO  epoch 4 training [time: 0.95s, train loss: 9263.2325]\n",
      "14 Apr 05:34    INFO  epoch 4 evaluating [time: 162.70s, valid_score: 0.197700]\n",
      "14 Apr 05:34    INFO  valid result: \n",
      "recall@10 : 0.1977    mrr@10 : 0.5095    ndcg@10 : 0.3265    hit@10 : 0.8555    precision@10 : 0.3083    map@10 : 0.1998\n",
      "14 Apr 05:34    INFO  Saving current: saved/RecVAE-Apr-14-2022_05-21-23.pth\n",
      "14 Apr 05:34    INFO  Loading model structure and parameters from saved/RecVAE-Apr-14-2022_05-21-23.pth\n",
      "14 Apr 05:36    INFO  best valid : OrderedDict([('recall@10', 0.1977), ('mrr@10', 0.5095), ('ndcg@10', 0.3265), ('hit@10', 0.8555), ('precision@10', 0.3083), ('map@10', 0.1998)])\n",
      "14 Apr 05:36    INFO  test result: OrderedDict([('recall@10', 0.1762), ('mrr@10', 0.4808), ('ndcg@10', 0.2938), ('hit@10', 0.8335), ('precision@10', 0.2758), ('map@10', 0.1729)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 16.07 mins\n",
      "{'best_valid_score': 0.1977, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.1977), ('mrr@10', 0.5095), ('ndcg@10', 0.3265), ('hit@10', 0.8555), ('precision@10', 0.3083), ('map@10', 0.1998)]), 'test_result': OrderedDict([('recall@10', 0.1762), ('mrr@10', 0.4808), ('ndcg@10', 0.2938), ('hit@10', 0.8335), ('precision@10', 0.2758), ('map@10', 0.1729)])}\n",
      "running LightGCN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 05:36    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/input/data/recbole\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.01\n",
      "neg_sampling = {'uniform': 1}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'uni50'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user\n",
      "ITEM_ID_FIELD = item\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user', 'item', 'rating', 'timestamp'], 'user': ['user'], 'item': ['item']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "n_layers = 2\n",
      "reg_weight = 1e-05\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 1, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'by', 'by': 50, 'distribution': 'uniform'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/opt/ml/input/code/recbole/Recbole.ipynb Cell 18'\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m run_recbole(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=26'>27</a>\u001b[0m         model\u001b[39m=\u001b[39mmodel_name,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=27'>28</a>\u001b[0m         dataset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecbole\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=28'>29</a>\u001b[0m         config_file_list\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m/opt/ml/input/data/recbole/config.yaml\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=29'>30</a>\u001b[0m         config_dict\u001b[39m=\u001b[39mparameter_dict,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=30'>31</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=31'>32</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m run_recbole(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=33'>34</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=34'>35</a>\u001b[0m         dataset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrecbole\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=35'>36</a>\u001b[0m         config_file_list\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m/opt/ml/input/data/recbole/config.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.183.225/opt/ml/input/code/recbole/Recbole.ipynb#ch0000016vscode-remote?line=36'>37</a>\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/quick_start/quick_start.py:41\u001b[0m, in \u001b[0;36mrun_recbole\u001b[0;34m(model, dataset, config_file_list, config_dict, saved)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/quick_start/quick_start.py?line=37'>38</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(config)\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/quick_start/quick_start.py?line=39'>40</a>\u001b[0m \u001b[39m# dataset filtering\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/quick_start/quick_start.py?line=40'>41</a>\u001b[0m dataset \u001b[39m=\u001b[39m create_dataset(config)\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/quick_start/quick_start.py?line=41'>42</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(dataset)\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/quick_start/quick_start.py?line=43'>44</a>\u001b[0m \u001b[39m# dataset splitting\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/utils.py:68\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/utils.py?line=64'>65</a>\u001b[0m         logger\u001b[39m.\u001b[39minfo(set_color(\u001b[39m'\u001b[39m\u001b[39mLoad filtered dataset from\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpink\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: [\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/utils.py?line=65'>66</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m dataset\n\u001b[0;32m---> <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/utils.py?line=67'>68</a>\u001b[0m dataset \u001b[39m=\u001b[39m dataset_class(config)\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/utils.py?line=68'>69</a>\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39msave_dataset\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/utils.py?line=69'>70</a>\u001b[0m     dataset\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:96\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=93'>94</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=94'>95</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m getLogger()\n\u001b[0;32m---> <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=95'>96</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_from_scratch()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:106\u001b[0m, in \u001b[0;36mDataset._from_scratch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=103'>104</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_preset()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=104'>105</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_field_from_config()\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=105'>106</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_path)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=106'>107</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_alias()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=107'>108</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_processing()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:247\u001b[0m, in \u001b[0;36mDataset._load_data\u001b[0;34m(self, token, dataset_path)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=244'>245</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(dataset_path):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=245'>246</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=246'>247</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_inter_feat(token, dataset_path)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=247'>248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_user_or_item_feat(token, dataset_path, FeatureSource\u001b[39m.\u001b[39mUSER, \u001b[39m'\u001b[39m\u001b[39muid_field\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=248'>249</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_user_or_item_feat(token, dataset_path, FeatureSource\u001b[39m.\u001b[39mITEM, \u001b[39m'\u001b[39m\u001b[39miid_field\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:270\u001b[0m, in \u001b[0;36mDataset._load_inter_feat\u001b[0;34m(self, token, dataset_path)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=266'>267</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(inter_feat_path):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=267'>268</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00minter_feat_path\u001b[39m}\u001b[39;00m\u001b[39m not exist.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=269'>270</a>\u001b[0m inter_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_feat(inter_feat_path, FeatureSource\u001b[39m.\u001b[39;49mINTERACTION)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=270'>271</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInteraction feature loaded successfully from [\u001b[39m\u001b[39m{\u001b[39;00minter_feat_path\u001b[39m}\u001b[39;00m\u001b[39m].\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=271'>272</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minter_feat \u001b[39m=\u001b[39m inter_feat\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:438\u001b[0m, in \u001b[0;36mDataset._load_feat\u001b[0;34m(self, filepath, source)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=434'>435</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo columns has been loaded from [\u001b[39m\u001b[39m{\u001b[39;00msource\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=435'>436</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=437'>438</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=438'>439</a>\u001b[0m     filepath, delimiter\u001b[39m=\u001b[39;49mfield_separator, usecols\u001b[39m=\u001b[39;49musecols, dtype\u001b[39m=\u001b[39;49mdtype, encoding\u001b[39m=\u001b[39;49mencoding, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=439'>440</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=440'>441</a>\u001b[0m df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m columns\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py?line=442'>443</a>\u001b[0m seq_separator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mseq_separator\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=579'>580</a>\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=580'>581</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1250\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1247'>1248</a>\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1248'>1249</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1249'>1250</a>\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1250'>1251</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1251'>1252</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py:238\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=235'>236</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, rows: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=236'>237</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=237'>238</a>\u001b[0m         content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_lines(rows)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=238'>239</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=239'>240</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py:1091\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=1087'>1088</a>\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=1089'>1090</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=1090'>1091</a>\u001b[0m     new_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_iter_line(row_num\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos \u001b[39m+\u001b[39;49m rows \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=1091'>1092</a>\u001b[0m     rows \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=1093'>1094</a>\u001b[0m     \u001b[39mif\u001b[39;00m new_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py:760\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=756'>757</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=757'>758</a>\u001b[0m     \u001b[39m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=758'>759</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=759'>760</a>\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=760'>761</a>\u001b[0m     \u001b[39m# for mypy\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py?line=761'>762</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(line, \u001b[39mlist\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_list = [\"Pop\", \"ItemKNN\", \"BPR\", \"NeuMF\", \"RecVAE\", \"LightGCN\"] # General\n",
    "model_list += [\"FFM\", \"DeepFM\"] # Context-aware\n",
    "model_list += [\"GRU4Rec\", \"SHAN\"] # Sequential\n",
    "for model_name in model_list:\n",
    "    print(f\"running {model_name}...\")\n",
    "    start = time.time()\n",
    "    result = run(model_name)\n",
    "    t = time.time() - start\n",
    "    print(f\"It took {t/60:.2f} mins\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
